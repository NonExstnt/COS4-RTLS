{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62fe6a3f",
   "metadata": {},
   "source": [
    "# Phase 1: Station Boundary Detection\n",
    "\n",
    "This notebook identifies distinct stations/zones where groups spend time during the workshop using clustering algorithms.\n",
    "\n",
    "## Objectives:\n",
    "- Visualize raw RTLS data\n",
    "- Apply K-Means clustering to identify stations\n",
    "- Use DBSCAN as an alternative clustering method\n",
    "- Export station centroids and assignments\n",
    "\n",
    "## Output:\n",
    "- Station centroids (coordinates)\n",
    "- Data with station assignments\n",
    "- Clustering model and scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2adfc96",
   "metadata": {},
   "source": [
    "## Workshop Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b15f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# WORKSHOP SELECTION\n",
    "# ============================================\n",
    "# Change this to analyze a different workshop\n",
    "# Valid options: \"Workshop1\", \"Workshop2\", \"Workshop3\"\n",
    "\n",
    "WORKSHOP = \"Workshop1\"  # ðŸ‘ˆ CHANGE THIS VALUE\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print(f\"ðŸŽ¯ Selected Workshop: {WORKSHOP}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"This analysis will run on {WORKSHOP} data only.\")\n",
    "print(f\"{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb17d5",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bf5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for the selected workshop\n",
    "data_file = f'../data/raw/{WORKSHOP}.csv'\n",
    "\n",
    "print(f\"Loading data from: {data_file}\")\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# Convert time to datetime\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Sort by group and time\n",
    "df = df.sort_values(['name', 'time']).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ðŸ“Š {WORKSHOP} Dataset Summary\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Date Range: {df['time'].min()} to {df['time'].max()}\")\n",
    "print(f\"Groups in this workshop: {sorted(df['name'].unique())}\")\n",
    "print(f\"Number of groups: {df['name'].nunique()}\")\n",
    "print(f\"Total Data Points: {len(df):,}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea795890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data exploration\n",
    "print(\"Coordinate Statistics:\")\n",
    "print(df[['x', 'y', 'z']].describe())\n",
    "\n",
    "print(\"\\nData Points per Group:\")\n",
    "print(df.groupby('name').size().to_frame('count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d2bdf",
   "metadata": {},
   "source": [
    "## 1.1 Visualize Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe47c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all data points in 2D space\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: All points colored by group\n",
    "for group in df['name'].unique():\n",
    "    group_data = df[df['name'] == group]\n",
    "    axes[0].scatter(group_data['x'], group_data['y'], alpha=0.3, s=10, label=group)\n",
    "axes[0].set_xlabel('X Coordinate (m)')\n",
    "axes[0].set_ylabel('Y Coordinate (m)')\n",
    "axes[0].set_title('All Data Points by Group')\n",
    "axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Density heatmap\n",
    "axes[1].hexbin(df['x'], df['y'], gridsize=30, cmap='YlOrRd', mincnt=1)\n",
    "axes[1].set_xlabel('X Coordinate (m)')\n",
    "axes[1].set_ylabel('Y Coordinate (m)')\n",
    "axes[1].set_title('Location Density Heatmap')\n",
    "plt.colorbar(axes[1].collections[0], ax=axes[1], label='Point Density')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"High-density areas likely represent stations where groups spent significant time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8eec59",
   "metadata": {},
   "source": [
    "## 1.2 K-Means Clustering: Find Optimal Number of Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c546216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare clustering data (use X, Y coordinates)\n",
    "coords = df[['x', 'y']].values\n",
    "\n",
    "# Standardize coordinates for better clustering\n",
    "scaler = StandardScaler()\n",
    "coords_scaled = scaler.fit_transform(coords)\n",
    "\n",
    "# Sample data for faster computation (if dataset is large)\n",
    "sample_size = min(20000, len(df))\n",
    "sample_idx = np.random.choice(len(df), sample_size, replace=False)\n",
    "coords_sample = coords_scaled[sample_idx]\n",
    "\n",
    "print(f\"Using {sample_size:,} sample points for optimal k analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538580fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method and silhouette analysis\n",
    "k_range = range(2, 16)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(coords_sample)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(coords_sample, labels))\n",
    "    print(f\"k={k}: Inertia={kmeans.inertia_:.2f}, Silhouette={silhouette_scores[-1]:.3f}\")\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Elbow curve\n",
    "axes[0].plot(k_range, inertias, 'bo-', linewidth=2)\n",
    "axes[0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[0].set_ylabel('Inertia (Within-cluster Sum of Squares)', fontsize=12)\n",
    "axes[0].set_title('Elbow Method', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Silhouette scores\n",
    "axes[1].plot(k_range, silhouette_scores, 'ro-', linewidth=2)\n",
    "axes[1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "axes[1].set_title('Silhouette Analysis', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "best_k_silhouette = k_range[np.argmax(silhouette_scores)]\n",
    "axes[1].axvline(x=best_k_silhouette, color='green', linestyle='--', label=f'Best k={best_k_silhouette}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… Recommended number of stations (clusters): {best_k_silhouette}\")\n",
    "print(f\"   Silhouette score: {max(silhouette_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42efb96a",
   "metadata": {},
   "source": [
    "## 1.3 Apply K-Means with Optimal k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda64d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the optimal k (or manually set based on domain knowledge)\n",
    "optimal_k = best_k_silhouette  # You can override this: optimal_k = 6\n",
    "\n",
    "# Fit K-Means on full dataset\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df['station'] = kmeans.fit_predict(coords_scaled)\n",
    "\n",
    "# Get station centroids in original scale\n",
    "centroids_scaled = kmeans.cluster_centers_\n",
    "centroids_original = scaler.inverse_transform(centroids_scaled)\n",
    "\n",
    "# Create station info dataframe\n",
    "station_info = pd.DataFrame({\n",
    "    'station': range(optimal_k),\n",
    "    'centroid_x': centroids_original[:, 0],\n",
    "    'centroid_y': centroids_original[:, 1]\n",
    "})\n",
    "\n",
    "print(\"Station Centroids:\")\n",
    "print(station_info)\n",
    "print(f\"\\nPoints per station:\")\n",
    "print(df['station'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5bb8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize stations\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Plot all points colored by station\n",
    "scatter = ax.scatter(df['x'], df['y'], c=df['station'], cmap='tab10', alpha=0.4, s=20)\n",
    "\n",
    "# Plot centroids\n",
    "ax.scatter(station_info['centroid_x'], station_info['centroid_y'], \n",
    "           c='red', marker='X', s=500, edgecolors='black', linewidths=2,\n",
    "           label='Station Centroids', zorder=5)\n",
    "\n",
    "# Add station labels\n",
    "for idx, row in station_info.iterrows():\n",
    "    ax.annotate(f'Station {idx}', \n",
    "                xy=(row['centroid_x'], row['centroid_y']),\n",
    "                xytext=(10, 10), textcoords='offset points',\n",
    "                fontsize=12, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "ax.set_xlabel('X Coordinate (m)', fontsize=12)\n",
    "ax.set_ylabel('Y Coordinate (m)', fontsize=12)\n",
    "ax.set_title(f'{WORKSHOP}: Detected Stations (K-Means, k={optimal_k})', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=ax, label='Station ID')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2d1503",
   "metadata": {},
   "source": [
    "## 1.4 Alternative: DBSCAN Clustering (Density-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DBSCAN\n",
    "dbscan = DBSCAN(eps=0.3, min_samples=50)  # Adjust eps and min_samples based on data\n",
    "df['station_dbscan'] = dbscan.fit_predict(coords_scaled)\n",
    "\n",
    "n_clusters_dbscan = len(set(df['station_dbscan'])) - (1 if -1 in df['station_dbscan'] else 0)\n",
    "n_noise = list(df['station_dbscan']).count(-1)\n",
    "\n",
    "print(f\"DBSCAN Results:\")\n",
    "print(f\"  Number of stations detected: {n_clusters_dbscan}\")\n",
    "print(f\"  Noise points (not assigned to any station): {n_noise}\")\n",
    "print(f\"\\nPoints per station:\")\n",
    "print(df['station_dbscan'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a92d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize DBSCAN results\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Plot points (noise points in black)\n",
    "unique_labels = set(df['station_dbscan'])\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "for label, color in zip(unique_labels, colors):\n",
    "    if label == -1:\n",
    "        color = 'black'\n",
    "        marker_size = 10\n",
    "        alpha = 0.3\n",
    "        label_text = 'Noise'\n",
    "    else:\n",
    "        marker_size = 20\n",
    "        alpha = 0.5\n",
    "        label_text = f'Station {label}'\n",
    "    \n",
    "    mask = df['station_dbscan'] == label\n",
    "    ax.scatter(df[mask]['x'], df[mask]['y'], \n",
    "               c=[color], s=marker_size, alpha=alpha, label=label_text)\n",
    "\n",
    "ax.set_xlabel('X Coordinate (m)', fontsize=12)\n",
    "ax.set_ylabel('Y Coordinate (m)', fontsize=12)\n",
    "ax.set_title(f'{WORKSHOP}: DBSCAN Station Detection ({n_clusters_dbscan} stations)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Choose between K-Means and DBSCAN based on your domain knowledge.\")\n",
    "print(\"   Continuing with K-Means stations for subsequent phases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc5d56c",
   "metadata": {},
   "source": [
    "## Save Phase 1 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c311660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for this workshop\n",
    "output_dir = Path(f'../data/phase1_results/{WORKSHOP}')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save data with station assignments\n",
    "df[['name', 'x', 'y', 'z', 'time', 'station', 'station_dbscan']].to_csv(\n",
    "    output_dir / 'data_with_stations.csv', index=False\n",
    ")\n",
    "\n",
    "# Save station centroids\n",
    "station_info.to_csv(output_dir / 'station_centroids.csv', index=False)\n",
    "\n",
    "# Save K-Means model and scaler\n",
    "with open(output_dir / 'kmeans_model.pkl', 'wb') as f:\n",
    "    pickle.dump(kmeans, f)\n",
    "\n",
    "with open(output_dir / 'scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'workshop': WORKSHOP,\n",
    "    'optimal_k': optimal_k,\n",
    "    'silhouette_score': max(silhouette_scores),\n",
    "    'dbscan_clusters': n_clusters_dbscan,\n",
    "    'total_data_points': len(df)\n",
    "}\n",
    "pd.DataFrame([metadata]).to_csv(output_dir / 'phase1_metadata.csv', index=False)\n",
    "\n",
    "print(f\"âœ… Phase 1 results saved to {output_dir}/\")\n",
    "print(f\"\\nSaved files:\")\n",
    "print(f\"  â€¢ data_with_stations.csv - Data with station assignments\")\n",
    "print(f\"  â€¢ station_centroids.csv - Station centroid coordinates\")\n",
    "print(f\"  â€¢ kmeans_model.pkl - Trained K-Means model\")\n",
    "print(f\"  â€¢ scaler.pkl - StandardScaler for coordinates\")\n",
    "print(f\"  â€¢ phase1_metadata.csv - Clustering metadata\")\n",
    "print(f\"\\nðŸŽ¯ Proceed to phase2_temporal_analysis.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
