{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2819a7bb",
   "metadata": {},
   "source": [
    "# Phase 3: Predictive Modeling\n",
    "\n",
    "This notebook builds machine learning models to predict:\n",
    "1. **Next Station Arrival Time**: When will a group reach the next station?\n",
    "2. **Total Completion Time**: How long until a group finishes all stations?\n",
    "\n",
    "## Prerequisites:\n",
    "- Complete Phase 1 (Station Detection)\n",
    "- Complete Phase 2 (Temporal Analysis)\n",
    "- Phase 1 & 2 outputs must exist in respective directories\n",
    "\n",
    "## Objectives:\n",
    "- Engineer features from temporal data\n",
    "- Train Random Forest model for next station prediction\n",
    "- Train Gradient Boosting model for completion time prediction\n",
    "- Evaluate model performance\n",
    "\n",
    "## Output:\n",
    "- Trained models\n",
    "- Prediction results\n",
    "- Feature importance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ddd538",
   "metadata": {},
   "source": [
    "## Workshop Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b90b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# WORKSHOP SELECTION\n",
    "# ============================================\n",
    "# Must match the workshop used in Phase 1 & 2\n",
    "# Valid options: \"Workshop1\", \"Workshop2\", \"Workshop3\"\n",
    "\n",
    "WORKSHOP = \"Workshop2\"  # ðŸ‘ˆ CHANGE THIS VALUE\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print(f\"ðŸŽ¯ Selected Workshop: {WORKSHOP}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Loading Phase 1 & 2 results for {WORKSHOP}...\")\n",
    "print(f\"{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb03f5a",
   "metadata": {},
   "source": [
    "## Setup and Load Previous Phase Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ec2aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Phase 1 results\n",
    "phase1_dir = Path(f'../data/phase1_results/{WORKSHOP}')\n",
    "phase2_dir = Path(f'../data/phase2_results/{WORKSHOP}')\n",
    "\n",
    "# Check if previous phases exist\n",
    "if not phase1_dir.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Phase 1 results not found for {WORKSHOP}.\\n\"\n",
    "        f\"Please run phase1_station_detection.ipynb first!\"\n",
    "    )\n",
    "\n",
    "if not phase2_dir.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Phase 2 results not found for {WORKSHOP}.\\n\"\n",
    "        f\"Please run phase2_temporal_analysis.ipynb first!\"\n",
    "    )\n",
    "\n",
    "# Load station centroids from Phase 1\n",
    "station_info = pd.read_csv(phase1_dir / 'station_centroids.csv')\n",
    "\n",
    "# Load visits data from Phase 2\n",
    "visits_df = pd.read_csv(phase2_dir / 'station_visits.csv')\n",
    "visits_df['start_time'] = pd.to_datetime(visits_df['start_time'])\n",
    "visits_df['end_time'] = pd.to_datetime(visits_df['end_time'])\n",
    "\n",
    "# Load travel times from Phase 2\n",
    "travel_df = pd.read_csv(phase2_dir / 'travel_times.csv')\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ðŸ“Š Loaded Previous Phase Results for {WORKSHOP}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Stations: {len(station_info)}\")\n",
    "print(f\"Station visits: {len(visits_df)}\")\n",
    "print(f\"Transitions: {len(travel_df)}\")\n",
    "print(f\"Groups: {sorted(visits_df['group'].unique())}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a5c0c5",
   "metadata": {},
   "source": [
    "## 3.1 Feature Engineering for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ef44b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features for predicting next station arrival\n",
    "prediction_data = []\n",
    "\n",
    "for group, group_visits in visits_df.groupby('group'):\n",
    "    group_visits = group_visits.sort_values('start_time').reset_index(drop=True)\n",
    "    \n",
    "    for i in range(len(group_visits) - 1):\n",
    "        current = group_visits.iloc[i]\n",
    "        next_visit = group_visits.iloc[i + 1]\n",
    "        \n",
    "        # Calculate time to next station\n",
    "        time_to_next = (next_visit['start_time'] - current['end_time']).total_seconds() / 60\n",
    "        \n",
    "        # Get centroid coordinates\n",
    "        current_centroid = station_info[station_info['station'] == current['station']].iloc[0]\n",
    "        next_centroid = station_info[station_info['station'] == next_visit['station']].iloc[0]\n",
    "        \n",
    "        # Calculate Euclidean distance\n",
    "        distance = np.sqrt(\n",
    "            (next_centroid['centroid_x'] - current_centroid['centroid_x'])**2 + \n",
    "            (next_centroid['centroid_y'] - current_centroid['centroid_y'])**2\n",
    "        )\n",
    "        \n",
    "        prediction_data.append({\n",
    "            'group': group,\n",
    "            'current_station': current['station'],\n",
    "            'next_station': next_visit['station'],\n",
    "            'visit_number': i,  # Which visit in sequence\n",
    "            'current_dwell_time': current['duration_minutes'],\n",
    "            'distance_to_next': distance,\n",
    "            'time_of_day_hour': current['end_time'].hour + current['end_time'].minute / 60,\n",
    "            'elapsed_time_minutes': (current['end_time'] - group_visits.iloc[0]['start_time']).total_seconds() / 60,\n",
    "            'avg_prev_dwell': group_visits.iloc[:i+1]['duration_minutes'].mean() if i > 0 else current['duration_minutes'],\n",
    "            'target_time_to_next': time_to_next  # Target variable\n",
    "        })\n",
    "\n",
    "pred_df = pd.DataFrame(prediction_data)\n",
    "\n",
    "print(f\"Prediction dataset size: {len(pred_df)}\")\n",
    "print(f\"\\nFeatures: {[col for col in pred_df.columns if col != 'target_time_to_next']}\")\n",
    "print(f\"\\nTarget variable: target_time_to_next (minutes to reach next station)\")\n",
    "\n",
    "pred_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15da9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlations\n",
    "numeric_cols = ['visit_number', 'current_dwell_time', 'distance_to_next', \n",
    "                'time_of_day_hour', 'elapsed_time_minutes', 'avg_prev_dwell', 'target_time_to_next']\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pred_df[numeric_cols].corr(), annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title(f'{WORKSHOP}: Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c27caf4",
   "metadata": {},
   "source": [
    "## 3.2 Model 1: Predict Time to Next Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173840b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "feature_cols = ['current_station', 'next_station', 'visit_number', 'current_dwell_time', \n",
    "                'distance_to_next', 'time_of_day_hour', 'elapsed_time_minutes', 'avg_prev_dwell']\n",
    "\n",
    "X = pred_df[feature_cols]\n",
    "y = pred_df['target_time_to_next']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = rf_model.predict(X_train)\n",
    "y_pred_test = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Random Forest - Time to Next Station Prediction\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Training Set:\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_train, y_pred_train):.2f} minutes\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_train)):.2f} minutes\")\n",
    "print(f\"  RÂ²: {r2_score(y_train, y_pred_train):.3f}\")\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test, y_pred_test):.2f} minutes\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_test)):.2f} minutes\")\n",
    "print(f\"  RÂ²: {r2_score(y_test, y_pred_test):.3f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eac45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'], color='teal')\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title(f'{WORKSHOP}: Feature Importance for Next Station Arrival', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop Features:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d06dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(y_test, y_pred_test, alpha=0.5, s=30)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Time to Next Station (min)', fontsize=11)\n",
    "axes[0].set_ylabel('Predicted Time (min)', fontsize=11)\n",
    "axes[0].set_title('Predictions vs Actual', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "residuals = y_test - y_pred_test\n",
    "axes[1].scatter(y_pred_test, residuals, alpha=0.5, s=30)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted Time (min)', fontsize=11)\n",
    "axes[1].set_ylabel('Residuals (min)', fontsize=11)\n",
    "axes[1].set_title('Residual Plot', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c26b50",
   "metadata": {},
   "source": [
    "## 3.3 Model 2: Predict Total Completion Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd29e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total time for each group to complete all stations\n",
    "completion_data = []\n",
    "\n",
    "for group, group_visits in visits_df.groupby('group'):\n",
    "    group_visits = group_visits.sort_values('start_time')\n",
    "    \n",
    "    if len(group_visits) < 2:\n",
    "        continue\n",
    "    \n",
    "    start_time = group_visits.iloc[0]['start_time']\n",
    "    end_time = group_visits.iloc[-1]['end_time']\n",
    "    total_time = (end_time - start_time).total_seconds() / 60\n",
    "    \n",
    "    completion_data.append({\n",
    "        'group': group,\n",
    "        'total_stations_visited': len(group_visits),\n",
    "        'unique_stations': group_visits['station'].nunique(),\n",
    "        'avg_dwell_time': group_visits['duration_minutes'].mean(),\n",
    "        'total_dwell_time': group_visits['duration_minutes'].sum(),\n",
    "        'first_station': group_visits.iloc[0]['station'],\n",
    "        'start_hour': start_time.hour + start_time.minute / 60,\n",
    "        'total_completion_time': total_time  # Target\n",
    "    })\n",
    "\n",
    "completion_df = pd.DataFrame(completion_data)\n",
    "\n",
    "print(f\"Groups analyzed: {len(completion_df)}\")\n",
    "print(f\"\\nCompletion Time Statistics:\")\n",
    "print(completion_df['total_completion_time'].describe())\n",
    "\n",
    "completion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f33f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for completion time prediction\n",
    "completion_features = ['total_stations_visited', 'unique_stations', 'avg_dwell_time', \n",
    "                       'first_station', 'start_hour']\n",
    "\n",
    "X_comp = completion_df[completion_features]\n",
    "y_comp = completion_df['total_completion_time']\n",
    "\n",
    "# Split\n",
    "X_train_comp, X_test_comp, y_train_comp, y_test_comp = train_test_split(\n",
    "    X_comp, y_comp, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "gb_model.fit(X_train_comp, y_train_comp)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_comp = gb_model.predict(X_train_comp)\n",
    "y_pred_test_comp = gb_model.predict(X_test_comp)\n",
    "\n",
    "# Evaluate\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Gradient Boosting - Total Completion Time Prediction\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Training Set:\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_train_comp, y_pred_train_comp):.2f} minutes\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_train_comp, y_pred_train_comp)):.2f} minutes\")\n",
    "print(f\"  RÂ²: {r2_score(y_train_comp, y_pred_train_comp):.3f}\")\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test_comp, y_pred_test_comp):.2f} minutes\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test_comp, y_pred_test_comp)):.2f} minutes\")\n",
    "print(f\"  RÂ²: {r2_score(y_test_comp, y_pred_test_comp):.3f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f4a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for completion time\n",
    "comp_importance = pd.DataFrame({\n",
    "    'feature': completion_features,\n",
    "    'importance': gb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(comp_importance['feature'], comp_importance['importance'], color='darkgreen')\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title(f'{WORKSHOP}: Feature Importance for Total Completion Time', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop Features:\")\n",
    "print(comp_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47554275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize completion time predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(y_test_comp, y_pred_test_comp, alpha=0.6, s=80, color='purple')\n",
    "axes[0].plot([y_test_comp.min(), y_test_comp.max()], \n",
    "             [y_test_comp.min(), y_test_comp.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Completion Time (min)', fontsize=11)\n",
    "axes[0].set_ylabel('Predicted Completion Time (min)', fontsize=11)\n",
    "axes[0].set_title('Completion Time: Predictions vs Actual', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution comparison\n",
    "axes[1].hist(y_test_comp, bins=15, alpha=0.5, label='Actual', color='blue')\n",
    "axes[1].hist(y_pred_test_comp, bins=15, alpha=0.5, label='Predicted', color='orange')\n",
    "axes[1].set_xlabel('Completion Time (min)', fontsize=11)\n",
    "axes[1].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1].set_title('Distribution: Actual vs Predicted', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f757269b",
   "metadata": {},
   "source": [
    "## Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1843f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(f\"PHASE 3 PREDICTIVE MODELING SUMMARY - {WORKSHOP}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nðŸ”® Model 1: Time to Next Station\")\n",
    "print(f\"  Algorithm: Random Forest Regressor\")\n",
    "print(f\"  Training samples: {len(X_train)}\")\n",
    "print(f\"  Test samples: {len(X_test)}\")\n",
    "print(f\"  Test MAE: {mean_absolute_error(y_test, y_pred_test):.2f} minutes\")\n",
    "print(f\"  Test RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_test)):.2f} minutes\")\n",
    "print(f\"  Test RÂ²: {r2_score(y_test, y_pred_test):.3f}\")\n",
    "print(f\"  Most important feature: {feature_importance.iloc[0]['feature']}\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Model 2: Total Completion Time\")\n",
    "print(f\"  Algorithm: Gradient Boosting Regressor\")\n",
    "print(f\"  Training samples: {len(X_train_comp)}\")\n",
    "print(f\"  Test samples: {len(X_test_comp)}\")\n",
    "print(f\"  Test MAE: {mean_absolute_error(y_test_comp, y_pred_test_comp):.2f} minutes\")\n",
    "print(f\"  Test RMSE: {np.sqrt(mean_squared_error(y_test_comp, y_pred_test_comp)):.2f} minutes\")\n",
    "print(f\"  Test RÂ²: {r2_score(y_test_comp, y_pred_test_comp):.3f}\")\n",
    "print(f\"  Most important feature: {comp_importance.iloc[0]['feature']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ’¡ Recommendations:\")\n",
    "print(\"  1. Fine-tune hyperparameters for better performance\")\n",
    "print(\"  2. Add more features (environmental, group-specific)\")\n",
    "print(\"  3. Try advanced models (XGBoost, LightGBM, Neural Networks)\")\n",
    "print(\"  4. Implement cross-validation for robust evaluation\")\n",
    "print(\"  5. Deploy models for real-time predictions\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ece0ceb",
   "metadata": {},
   "source": [
    "## Save Phase 3 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a3e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(f'../data/phase3_results/{WORKSHOP}')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save prediction features and results\n",
    "pred_df['predicted_time_to_next'] = rf_model.predict(pred_df[feature_cols])\n",
    "pred_df.to_csv(output_dir / 'next_station_predictions.csv', index=False)\n",
    "\n",
    "completion_df['predicted_completion_time'] = gb_model.predict(completion_df[completion_features])\n",
    "completion_df.to_csv(output_dir / 'completion_time_predictions.csv', index=False)\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance.to_csv(output_dir / 'next_station_feature_importance.csv', index=False)\n",
    "comp_importance.to_csv(output_dir / 'completion_feature_importance.csv', index=False)\n",
    "\n",
    "# Save models\n",
    "with open(output_dir / 'rf_next_station_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "\n",
    "with open(output_dir / 'gb_completion_model.pkl', 'wb') as f:\n",
    "    pickle.dump(gb_model, f)\n",
    "\n",
    "# Save model performance metrics\n",
    "metrics = {\n",
    "    'workshop': WORKSHOP,\n",
    "    'next_station_test_mae': mean_absolute_error(y_test, y_pred_test),\n",
    "    'next_station_test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "    'next_station_test_r2': r2_score(y_test, y_pred_test),\n",
    "    'completion_test_mae': mean_absolute_error(y_test_comp, y_pred_test_comp),\n",
    "    'completion_test_rmse': np.sqrt(mean_squared_error(y_test_comp, y_pred_test_comp)),\n",
    "    'completion_test_r2': r2_score(y_test_comp, y_pred_test_comp)\n",
    "}\n",
    "pd.DataFrame([metrics]).to_csv(output_dir / 'model_metrics.csv', index=False)\n",
    "\n",
    "print(f\"âœ… Phase 3 results saved to {output_dir}/\")\n",
    "print(f\"\\nSaved files:\")\n",
    "print(f\"  â€¢ next_station_predictions.csv - Predictions for next station arrival\")\n",
    "print(f\"  â€¢ completion_time_predictions.csv - Completion time predictions\")\n",
    "print(f\"  â€¢ next_station_feature_importance.csv - Feature importance for Model 1\")\n",
    "print(f\"  â€¢ completion_feature_importance.csv - Feature importance for Model 2\")\n",
    "print(f\"  â€¢ rf_next_station_model.pkl - Trained Random Forest model\")\n",
    "print(f\"  â€¢ gb_completion_model.pkl - Trained Gradient Boosting model\")\n",
    "print(f\"  â€¢ model_metrics.csv - Performance metrics\")\n",
    "print(f\"\\nðŸŽ‰ All three phases completed for {WORKSHOP}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COS4-RTLS (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
